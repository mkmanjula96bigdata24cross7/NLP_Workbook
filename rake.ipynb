{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = Rake()\n",
    "text_content = \"\"\"\n",
    "Sources tell us that Google is acquiring Kaggle, a platform that hosts data science and machine learning\n",
    "competitions. Details about the transaction remain somewhat vague , but given that Google is hosting\n",
    "its Cloud Next conference in San Francisco this week, the official announcement could come as early\n",
    "as tomorrow. Reached by phone, Kaggle co-founder CEO Anthony Goldbloom declined to deny that the\n",
    "acquisition is happening. Google itself declined 'to comment on rumors'.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.extract_keywords_from_text(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['founder ceo anthony goldbloom declined',\n",
       " 'transaction remain somewhat vague',\n",
       " 'official announcement could come',\n",
       " 'sources tell us',\n",
       " 'machine learning competitions',\n",
       " 'hosts data science',\n",
       " 'cloud next conference',\n",
       " 'san francisco',\n",
       " \"rumors '.\",\n",
       " 'kaggle co',\n",
       " 'acquiring kaggle',\n",
       " 'declined',\n",
       " 'week',\n",
       " 'tomorrow',\n",
       " 'reached',\n",
       " 'platform',\n",
       " 'phone',\n",
       " 'hosting',\n",
       " 'happening',\n",
       " 'google',\n",
       " 'given',\n",
       " 'early',\n",
       " 'details',\n",
       " 'deny',\n",
       " 'comment',\n",
       " 'acquisition']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.get_ranked_phrases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23.0, 'founder ceo anthony goldbloom declined'),\n",
       " (16.0, 'transaction remain somewhat vague'),\n",
       " (16.0, 'official announcement could come'),\n",
       " (9.0, 'sources tell us'),\n",
       " (9.0, 'machine learning competitions'),\n",
       " (9.0, 'hosts data science'),\n",
       " (9.0, 'cloud next conference'),\n",
       " (4.0, 'san francisco'),\n",
       " (4.0, \"rumors '.\"),\n",
       " (4.0, 'kaggle co'),\n",
       " (4.0, 'acquiring kaggle'),\n",
       " (3.0, 'declined'),\n",
       " (1.0, 'week'),\n",
       " (1.0, 'tomorrow'),\n",
       " (1.0, 'reached'),\n",
       " (1.0, 'platform'),\n",
       " (1.0, 'phone'),\n",
       " (1.0, 'hosting'),\n",
       " (1.0, 'happening'),\n",
       " (1.0, 'google'),\n",
       " (1.0, 'given'),\n",
       " (1.0, 'early'),\n",
       " (1.0, 'details'),\n",
       " (1.0, 'deny'),\n",
       " (1.0, 'comment'),\n",
       " (1.0, 'acquisition')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.get_ranked_phrases_with_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=r.extract_keywords_from_sentences(text_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    " \n",
    "stemmer = PorterStemmer()\n",
    "lemmatiser = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\devim2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stem studying: studi\n",
      "Lemmatise studying: studying\n",
      "Lemmatise studying: study\n"
     ]
    }
   ],
   "source": [
    "print(\"Stem %s: %s\" % (\"studying\", stemmer.stem(\"studying\")))\n",
    "print(\"Lemmatise %s: %s\" % (\"studying\", lemmatiser.lemmatize(\"studying\")))\n",
    "print(\"Lemmatise %s: %s\" % (\"studying\", lemmatiser.lemmatize(\"studying\", pos=\"v\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\devim2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sources', 'NNS'), ('tell', 'VBP'), ('us', 'PRP'), ('that', 'IN'), ('Google', 'NNP'), ('is', 'VBZ'), ('acquiring', 'VBG'), ('Kaggle', 'NNP'), (',', ','), ('a', 'DT'), ('platform', 'NN'), ('that', 'WDT'), ('hosts', 'VBZ'), ('data', 'NNS'), ('science', 'NN'), ('and', 'CC'), ('machine', 'NN'), ('learning', 'NN'), ('competitions', 'NNS'), ('.', '.'), ('Details', 'NNS'), ('about', 'IN'), ('the', 'DT'), ('transaction', 'NN'), ('remain', 'VBP'), ('somewhat', 'RB'), ('vague', 'JJ'), (',', ','), ('but', 'CC'), ('given', 'VBN'), ('that', 'IN'), ('Google', 'NNP'), ('is', 'VBZ'), ('hosting', 'VBG'), ('its', 'PRP$'), ('Cloud', 'NNP'), ('Next', 'NNP'), ('conference', 'NN'), ('in', 'IN'), ('San', 'NNP'), ('Francisco', 'NNP'), ('this', 'DT'), ('week', 'NN'), (',', ','), ('the', 'DT'), ('official', 'JJ'), ('announcement', 'NN'), ('could', 'MD'), ('come', 'VB'), ('as', 'RB'), ('early', 'JJ'), ('as', 'IN'), ('tomorrow', 'NN'), ('.', '.'), ('Reached', 'VBN'), ('by', 'IN'), ('phone', 'NN'), (',', ','), ('Kaggle', 'NNP'), ('co-founder', 'NN'), ('CEO', 'NNP'), ('Anthony', 'NNP'), ('Goldbloom', 'NNP'), ('declined', 'VBD'), ('to', 'TO'), ('deny', 'VB'), ('that', 'IN'), ('the', 'DT'), ('acquisition', 'NN'), ('is', 'VBZ'), ('happening', 'VBG'), ('.', '.'), ('Google', 'NNP'), ('itself', 'PRP'), ('declined', 'VBD'), (\"'to\", 'CD'), ('comment', 'NN'), ('on', 'IN'), ('rumors', 'NNS'), (\"'\", 'POS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    " \n",
    "s = \"\"\"\n",
    "Sources tell us that Google is acquiring Kaggle, a platform that hosts data science and machine learning\n",
    "competitions. Details about the transaction remain somewhat vague , but given that Google is hosting\n",
    "its Cloud Next conference in San Francisco this week, the official announcement could come as early\n",
    "as tomorrow. Reached by phone, Kaggle co-founder CEO Anthony Goldbloom declined to deny that the\n",
    "acquisition is happening. Google itself declined 'to comment on rumors'.\n",
    "\"\"\"\n",
    "tokens = word_tokenize(s) # Generate list of tokens\n",
    "tokens_pos = pos_tag(tokens) \n",
    " \n",
    "print(tokens_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun=[]\n",
    "for i in range(len(tokens_pos)):\n",
    "    if(tokens_pos[i][1]=='NN'):\n",
    "        noun.append(tokens_pos[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['platform',\n",
       " 'science',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'transaction',\n",
       " 'conference',\n",
       " 'week',\n",
       " 'announcement',\n",
       " 'tomorrow',\n",
       " 'phone',\n",
       " 'co-founder',\n",
       " 'acquisition',\n",
       " 'comment']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting topia.termextract\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/b9/452257976ebee91d07c74bc4b34cfce416f45b94af1d62902ae39bf902cf/topia.termextract-1.1.0.tar.gz\n",
      "Requirement already satisfied: setuptools in c:\\users\\devim2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from topia.termextract) (40.2.0)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\devim2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from topia.termextract) (4.5.0)\n",
      "Building wheels for collected packages: topia.termextract\n",
      "  Running setup.py bdist_wheel for topia.termextract: started\n",
      "  Running setup.py bdist_wheel for topia.termextract: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\devim2\\AppData\\Local\\pip\\Cache\\wheels\\2f\\ec\\89\\a12badc5b41e41b4a6a3c4c1cb4d66b1c1281f3b43a21da441\n",
      "Successfully built topia.termextract\n",
      "Installing collected packages: topia.termextract\n",
      "Successfully installed topia.termextract-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install topia.termextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Class advice impossible in Python3.  Use the @implementer class decorator instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-a56ed2a993c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtopia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtermextract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36\\lib\\site-packages\\topia\\termextract\\tag.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m     \u001b[0mzope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITagger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36\\lib\\site-packages\\topia\\termextract\\tag.py\u001b[0m in \u001b[0;36mTagger\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mzope\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITagger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     rules = (\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\py36\\lib\\site-packages\\zope\\interface\\declarations.py\u001b[0m in \u001b[0;36mimplements\u001b[1;34m(*interfaces)\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# the coverage for this block there. :(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mPYTHON3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 483\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ADVICE_ERROR\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;34m'implementer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    484\u001b[0m     \u001b[0m_implements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"implements\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassImplements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Class advice impossible in Python3.  Use the @implementer class decorator instead."
     ]
    }
   ],
   "source": [
    "from topia.termextract import tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
